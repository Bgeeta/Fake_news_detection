# -*- coding: utf-8 -*-
"""Copy of major.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AT0agjhcdrtGSfic0csViC_k8KUNHlqM
"""

import pandas as pd
import matplotlib.pyplot as plt 
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns
from sklearn.ensemble import VotingClassifier,AdaBoostClassifier

from google.colab import drive #section2
drive.mount('/content/drive')

dataframe = pd.read_csv('/content/drive/MyDrive/forMajor/news.csv')
dataframe

dataframe.info()

dataframe.isnull().sum()

x = dataframe['text']
y = dataframe['label']

print(x)

print(y)

l=['Real','Fake']
print(y.value_counts())
plt.bar(l,y.value_counts())

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=5)

tfvect = TfidfVectorizer(stop_words='english',max_df=0.7)
tfid_x_train = tfvect.fit_transform(x_train)
tfid_x_test = tfvect.transform(x_test)

from sklearn.naive_bayes import MultinomialNB
c=MultinomialNB()
c.fit(tfid_x_train,y_train)

y_pred=c.predict(tfid_x_test)
score_nb=accuracy_score(y_test,y_pred)
print(f'Accuracy: {round(score_nb*100,2)}%')

from sklearn.metrics import precision_score
nb_p=precision_score(y_test,y_pred,average="binary",pos_label="REAL")
print("precision ",nb_p)

from sklearn.metrics import recall_score
nb_r=recall_score(y_test,y_pred,average="binary",pos_label="REAL")
print("recall",nb_r)

from sklearn.metrics import f1_score
nb_f1=f1_score(y_test,y_pred,average="binary",pos_label="REAL")
print("f1score",nb_f1)

cp = confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])
p=sns.heatmap(pd.DataFrame(cp),annot=True,cmap="YlGnBu",fmt='g')
print("Naive Bayes")
plt.title("Confusion matrix",y=1.1)
plt.ylabel("Actual label")
plt.xlabel("predicted label")
print(cp)

from sklearn.ensemble import RandomForestClassifier
estimators=[]
model1 = PassiveAggressiveClassifier(max_iter=50)
estimators.append(('pac1',model1))
model2=AdaBoostClassifier(base_estimator=RandomForestClassifier(random_state=101),
                          n_estimators=100,learning_rate=0.01)
estimators.append(('abc1',model2))

ensemble=VotingClassifier(estimators)
ensemble.fit(tfid_x_train,y_train)

y_pred1=ensemble.predict(tfid_x_test)

score_hm=accuracy_score(y_test,y_pred1)
print(f'Accuracy:{round(score_hm*100,2)}%')

from sklearn.metrics import precision_score
hm_p= precision_score(y_test,y_pred1,average="binary",pos_label="REAL")
print("precision",hm_p)

from sklearn.metrics import recall_score
hm_r=recall_score(y_test,y_pred1,average="binary",pos_label="REAL")
print("Recall",hm_r)

from sklearn.metrics import f1_score
hm_f1=f1_score(y_test,y_pred1,pos_label="REAL")
print("f1score",hm_f1)

cp = confusion_matrix(y_test,y_pred1, labels=['FAKE','REAL'])
p=sns.heatmap(pd.DataFrame(cp),annot=True,cmap="YlGnBu",fmt='g')
plt.title("Confusion matrix",y=1.1)
plt.ylabel("Actual label")
plt.xlabel("predicted label")
print(cp)

scores=[score_nb,score_hm]
algo=["Naive Bayes","PAC+ADAboost"]
plt.xlabel("Algorithms")
plt.ylabel("Accuracy score")
sns.barplot(x=algo,y=scores)

scores=[nb_p,hm_p]
algo=["Naive Bayes","PAC+ADABoost"]
plt.xlabel("Algorithms")
plt.ylabel("Precision")
sns.barplot(x=algo,y=scores)

scores=[nb_r,hm_r]
algo=["Naive Bayes","PAC+ADABoost"]
plt.xlabel("Algorithms")
plt.ylabel("Recall")
sns.barplot(x=algo,y=scores)

scores=[nb_f1,hm_f1]
algo=["Naive Bayes","PAC+ADABoost"]
plt.xlabel("Algorithms")
plt.ylabel("F1 score")
sns.barplot(x=algo,y=scores)

x_new=tfid_x_test[0]

yy=ensemble.predict(x_new)
if yy[0]=='FAKE':
  print("The article is fake")
else:
  print("The article is real")

x_new=tfid_x_test[1250]
print("Aritcle: ", list(x_test)[1250])
print("Actual Output: ", list(y_test)[1250])
print("Our Prediction: ")
yy=ensemble.predict(x_new)
if yy=='FAKE':
  print("The article is fake")
else:
  print("The article is real")

x_new=tfid_x_test[1250]
print("Aritcle: ", list(x_test)[1250])
print("Actual Output: ", list(y_test)[1250])
print("Our Prediction: ", end="")
yy=ensemble.predict(x_new)
if yy=='FAKE':
  print("The article is fake")
else:
  print("The article is real")

file1 = open("/content/drive/MyDrive/forMajor/RealArtical1.txt", "r")
articalContent = file1.read()
file1.close()
x = tfvect.transform([articalContent])
yy=ensemble.predict(x)
if yy=='FAKE':
  print("The article is fake")
else:
  print("The article is real")

file1 = open("/content/drive/MyDrive/forMajor/FakeArtical1.txt", "r")
articalContent = file1.read()
file1.close()
x = tfvect.transform([articalContent])
yy=ensemble.predict(x)
if yy=='FAKE':
  print("The article is fake")
else:
  print("The article is real")

fileName = input("Enter the filename to predict: ")
file1 = open("/content/drive/MyDrive/forMajor/"+fileName, "r")
articalContent = file1.read()
file1.close()

x = tfvect.transform([articalContent])
print("Aritcle: ", articalContent)
print("Actual Output: ", fileName[:4])
print("Our Prediction: ", end="")
yy=ensemble.predict(x)
if yy=='FAKE':
  print("The article is\033[1m Fake \033[0m")
else:
  print("The article is \033[1m Real \033[0m")